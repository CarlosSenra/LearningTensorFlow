{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### starting a basic sequence to sequence LSTM model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesEncoder(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super().__init__()\n",
    "    self.lstm = tf.keras.layers.LSTM(units, return_sequences=True, return_state=True)\n",
    "\n",
    "  def call(self, inputs, state=None):\n",
    "    outputs, state_h, state_c = self.lstm(inputs, initial_state=state)\n",
    "    return outputs, (state_h, state_c)\n",
    "\n",
    "class TimeSeriesDecoder(tf.keras.Model):\n",
    "  def __init__(self, units):\n",
    "    super().__init__()\n",
    "    self.lstm = tf.keras.layers.LSTM(units, return_sequences=True)\n",
    "    self.dense = tf.keras.layers.Dense(1)  # One output for predicted future value\n",
    "\n",
    "  def call(self, hidden_state):\n",
    "    outputs = self.lstm(None, initial_state=hidden_state)  # Pass None for inputs\n",
    "    predictions = self.dense(outputs)\n",
    "    return predictions\n",
    "\n",
    "class Seq2SeqLSTMForcast(tf.keras.Model):\n",
    "  def __init__(self, encoder_units, decoder_units):\n",
    "    super().__init__()\n",
    "    self.encoder = TimeSeriesEncoder(encoder_units)\n",
    "    self.decoder = TimeSeriesDecoder(decoder_units)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    encoder_outputs, encoder_hidden = self.encoder(inputs)\n",
    "\n",
    "    predictions = []\n",
    "    for _ in range(self.target_steps):  # Predict for target_steps (use internal attribute)\n",
    "      decoder_output = self.decoder(tf.expand_dims(encoder_outputs[:, -1, :], 0), encoder_hidden)\n",
    "      predictions.append(decoder_output)\n",
    "\n",
    "    predictions = tf.concat(predictions, axis=1)  # Concatenate predictions\n",
    "    return predictions\n",
    "  \n",
    "  # Generate random time series data function (replace with your data source)\n",
    "def generate_random_data(samples, timesteps, features):\n",
    "  data = np.random.rand(samples, timesteps, features)\n",
    "  # Optionally add trends, seasonality, or external factors here\n",
    "\n",
    "  return data.astype(np.float32)\n",
    "\n",
    "# Example usage\n",
    "model = Seq2SeqLSTMForcast(encoder_units=256, decoder_units=128)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = tf.keras.losses.MeanSquaredError()  # MSE for forecasting\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Generate sample data (replace with your actual data)\n",
    "past_data = generate_random_data(samples=100, timesteps=20, features=7)\n",
    "future_values = past_data[:, -1:, :]  # Take last timestep as future value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling LSTM.call().\n\n\u001b[1m'LSTMCell' object has no attribute 'kernel'\u001b[0m\n\nArguments received by LSTM.call():\n  • sequences=tf.Tensor(shape=(None, 20, 7), dtype=float32)\n  • initial_state=None\n  • mask=None\n  • training=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39mloss_function,optimizer\u001b[38;5;241m=\u001b[39moptimizer)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_data\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m, in \u001b[0;36mSeq2SeqLSTMForcast.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs):\n\u001b[0;32m---> 28\u001b[0m   encoder_outputs, encoder_hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m   predictions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_steps):  \u001b[38;5;66;03m# Predict for target_steps (use internal attribute)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 7\u001b[0m, in \u001b[0;36mTimeSeriesEncoder.call\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 7\u001b[0m   outputs, state_h, state_c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m outputs, (state_h, state_c)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling LSTM.call().\n\n\u001b[1m'LSTMCell' object has no attribute 'kernel'\u001b[0m\n\nArguments received by LSTM.call():\n  • sequences=tf.Tensor(shape=(None, 20, 7), dtype=float32)\n  • initial_state=None\n  • mask=None\n  • training=False"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss_function,optimizer=optimizer)\n",
    "\n",
    "model.fit(model.fit([past_data, past_data], past_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'target_steps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m----> 2\u001b[0m   predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m   loss \u001b[38;5;241m=\u001b[39m loss_function(future_values, predictions)\n\u001b[1;32m      5\u001b[0m gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-park/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-park/lib/python3.10/inspect.py:3186\u001b[0m, in \u001b[0;36mSignature.bind\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m/\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   3182\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[1;32m   3183\u001b[0m \u001b[38;5;124;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[1;32m   3184\u001b[0m \u001b[38;5;124;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[1;32m   3185\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow-park/lib/python3.10/inspect.py:3175\u001b[0m, in \u001b[0;36mSignature._bind\u001b[0;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[1;32m   3173\u001b[0m         arguments[kwargs_param\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m kwargs\n\u001b[1;32m   3174\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3175\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3176\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   3177\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[1;32m   3179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[0;31mTypeError\u001b[0m: got an unexpected keyword argument 'target_steps'"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "  predictions = model(past_data, target_steps=1)\n",
    "  loss = loss_function(future_values, predictions)\n",
    "\n",
    "gradients = tape.gradient(loss, model.trainable_variables)\n",
    "optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-park",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
